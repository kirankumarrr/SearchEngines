Elastic Search  ----->>> opensource
what?
--Real time distributed and analytic engine
--Open Source --dev using java
--based on Lucene engine on top of it we have REST interface
--Support Full-text and completely based on documents ---not tables and schemas --most of other search engines relay on this
--Used for Single Page application --how ?
why?
====Query++++
	--perform and combine many types of searches like structured, unstructured, geo, metric etc,...
====Analyze+++
	--help to understand billions of logs
	--provide aggregations which help you zoom out to explore trends & patterns in our data.
	
advantages?
====Scalablity++++
	--scale across multiple nodes when ur load been increased
====Really fast++++
	--performance
====Multilingual++++
	--support several languages
====Document Oriented++++
	--stored as doc and o/p will be only json
====Autocompletion & Instant Search++++
====Schema Free++++
	--stored in the form of doc
installation ::skip

Basic  Concepts:
	Near Real Time::
		--As soon as you insert the data into index it will available to search
	Cluster::
		--collection of 2 or more NODES that together holds the entire data.\
		--provide federated indexing and search capabilities across all the nodes and identified by a unique name--default(ElasticSearch)
	Node::
		--Single server which is part of cluster, stores data & participates in the cluster's indexing and search capabilities
	INDEX::
		--Collection of doc with similiar characteristics and is identified by name
		--can have multiple index
		

api convensions
apis
query dsl
mapping
analysis
modules





1) Full-text search engine
2) NoSQL database
3) Analytics engine
4) written in Java
5) Apache Lucene based (~solar)(its a search engine library)
6) Inverted indices
7) Easy to scale(~Elastic)
8) RESTFull interface(HTTP/JSON)  --->respose only json format --read all kind of formats no need to dev java classes like connectors 
9) Schemaless  -->its dynamic in nature for data types no need to create manually
	Explicit Mapping comes in when it guess wrong data-type :::mention type:integer
10)	Real-Time
11) ELK stack


RDMS          Elastic Search

Database       index

Table          Type

Row 			Document


Beside the Scences :
Cluster : collection of nodes 
index Structure:
	index --> commbinations of shards
	Shards  --> commbinations of segements
	Replica --> copies of shards data
	Node  --> if we have multiple nodes we make our search engine fast
	
writr query in elastic search

curl -XGET "http://localhost:9200/business/_search" -H 
	'Content-Type:application/json' -d'
	{
	"query":{
			"match_all":{}
		}
	}

	: here business ---> index
	
BackView:

::When we index or delete the docs :: We have primary and replica :: so these will update one after date so that those will be always in synch
	check video 7 for more info

document --> ElasticSearch --> Analysis --> InvertedIndexStructure --> Buffers --> shards(segments) --> Immutable InvertedIndex -->searchable

==========
Analysis:::
==========
Analyzer has 2 steps ::
.......INDEXING.....
a)Tokenizer --break sentence into words
b)Filter	
	Remove Stop Words
	Lowercasing
	Stemming
	synonyms
......SEARCH.......
	same thing as it done for INDEXING
=======Need to COnfigure+++++++++
this step we have to do before setting index 
Configure the index Structure
{
	"settings":{ --->(Higherlevel info)no.of.shards ? no.of replica
		...
	},
	"mapping":{ ---> Data types of Fields Inforamtion
		...
	},
}
but this is not right way to follow ES Structure
////////Setting Structure Manually by DEV//////
PUT /customers
{
	"settings":{ 
		"number_of_shards" : 2,
		"number_of_replicas" :1
	},
	"mapping":{}
}

PUT /customers/_mapping/online
{
	"properties" : {
		"name" : {
			"type" : "string", ///depcreated in latest versions ///better use "text"
			"analyzer" : "standard" // applied on the name field
		}
	}
}


Search DSL(Domain Specific Language) Component::::
	Query Context
	Filter Context
		---> Both of these can also be combined to form more complex queries
		
Query Context::
=============
	0-> GET  /courses/_search
		{
		"query":{
				"match_all":{}
			}
		}
		//Match all ---> "*"
	1->	GET  /courses/_search
		{
			"query":{
				"match":{
					"name" : "computers"
				}
			}
		}
		//Match ::: name:"computers"
	2-> GET  /courses/_search
		{  
		   "query":{  
			  "match":{  
				 "exists":{  
					"field":"professor.email"
				 }
			  }
		   }
		}
		//Match ::: check wheather field exist ::return data else not found
	3-> GET  /courses/_search
		{  
		   "query":{  
			  "bool":{  
				 "must":[  
					{  
					   "match":{  
						  "name":"computers"
					   }
					},
					{  
					   "match":{  
						  "room":"c4"
					   }
					}
				 ]
			  }
		   }
		}
		//to search for multiple fields
		4-> GET  /courses/_search
		{  
		   "query":{  
			  "bool":{  
				 "must":[  
					{  
					   "match":{  
						  "name":"computers"
					   }
					},
					{  
					   "match":{  
						  "room":"c4"
					   }
					}
				 ]
				 "must_not":[  
					{  
					   "match":{  
						  "professor.name":"bill"
					   }
					}
				 ]
			  }
		   }
		}
		//to search for multiple fields 
		a) must -- matchs what we want and return data-type
		b) must_not --if matches that data wont be returned
		5-> GET  /courses/_search
		{  
		   "query":{  
			  "bool":{  
				 "must":[  
					{  
					   "match":{  
						  "name":"computers"
					   }
					},
					{  
					   "match":{  
						  "room":"c4"
					   }
					}
				 ]
				 "must_not":[  
					{  
					   "match":{  
						  "professor.name":"bill"
					   }
					}
				 ]
				 "should" : [
					{  
					   "match":{  
						  "professor.name":"bill"
					   }
					}
					//ignored most in cases but we got one option to let know elastic that its required
				 ]
			  }
			  "minimum_should_match" : 1
		   }
		}